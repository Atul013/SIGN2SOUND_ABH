I need you to set up and train the Sign2Sound ASL Recognition model on this PC. This PC has 8GB VRAM with CUDA support for GPU-accelerated training. 

IMPORTANT: The repository is already cloned and the ASL dataset is already downloaded and extracted. Follow these steps exactly:

STEP 1: VERIFY CUDA INSTALLATION
Check CUDA and GPU availability:
```bash
nvidia-smi
# Should show your GPU with 8GB VRAM and CUDA version

nvcc --version
# Should show CUDA compiler version (11.x or 12.x)
```

STEP 2: SETUP ENVIRONMENT WITH CUDA
Navigate to project and create virtual environment with CUDA-enabled dependencies:
```bash
cd SIGN2SOUND_ABH
python -m venv venv
source venv/bin/activate  # Linux/Mac | Windows: venv\Scripts\activate
pip install --upgrade pip

# Install PyTorch with CUDA support (RECOMMENDED for better performance)
# For CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# OR for CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# OR install TensorFlow with CUDA (alternative)
pip install tensorflow[and-cuda]==2.15.0

# Install other dependencies
pip install -r requirements.txt

# Verify GPU is detected
python -c "import torch; print('CUDA Available:', torch.cuda.is_available()); print('GPU Name:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'); print('GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory / 1e9, 2) if torch.cuda.is_available() else 0, 'GB')"
```

STEP 3: DOWNLOAD MEDIAPIPE MODEL
Download the hand landmarker model:
```bash
mkdir -p models
wget -O models/hand_landmarker.task https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/latest/hand_landmarker.task
```
Or Windows PowerShell:
```powershell
New-Item -ItemType Directory -Force -Path models
Invoke-WebRequest -Uri "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/latest/hand_landmarker.task" -OutFile "models/hand_landmarker.task"
```

STEP 4: VERIFY DATASET STRUCTURE
Verify the ASL dataset is properly extracted:
```bash
ls ASL/ASL_Alphabet_Dataset/asl_alphabet_train/
# Should show: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z del nothing space

# Count images in one class (should be ~3000)
ls ASL/ASL_Alphabet_Dataset/asl_alphabet_train/A/ | wc -l
```

STEP 5: PREPROCESS DATASET
Extract hand landmarks from all images (~45 minutes):
```bash
python scripts/preprocess_asl_images.py --train-only --create-splits
python scripts/preprocess_asl_images.py --test-only
```

Verify preprocessing:
```bash
cat data/processed/train/preprocessing_stats.json
find data/processed/train -name "*.npy" | wc -l  # Should be ~74,000
```

STEP 6: OPTIMIZE FOR 8GB VRAM
Set appropriate batch size for 8GB VRAM:
```bash
# Verify batch_size is set to 32 in training/config.yaml (safe for 8GB)
cat training/config.yaml | grep batch_size
# Should show: batch_size: 32
```

STEP 7: TRAIN MODEL WITH CUDA
Start GPU-accelerated training (~2-3 hours):
```bash
# Set CUDA environment variables for optimal performance
export CUDA_VISIBLE_DEVICES=0
export TF_FORCE_GPU_ALLOW_GROWTH=true  # For TensorFlow
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512  # For PyTorch

python training/train.py --config training/config.yaml --use-cuda
```

Monitor progress in another terminal:
```bash
tail -f results/training_log.txt
```

Monitor GPU usage:
```bash
watch -n 1 nvidia-smi
```

STEP 8: EVALUATE MODEL
After training completes:
```bash
python training/evaluate.py --model checkpoints/best_model.h5 --use-cuda
```

STEP 9: TEST REAL-TIME INFERENCE
```bash
python inference/realtime_demo.py --model checkpoints/best_model.h5 --use-cuda
```

STEP 10: RUN WEB UI
```bash
cd ui
python app.py
# Open browser: http://localhost:5000
```

EXPECTED RESULTS WITH 8GB VRAM + CUDA:
- Preprocessing: 30-45 minutes (CPU-bound, MediaPipe)
- Training: 2-3 hours (CUDA-accelerated, batch_size=32)
- Test Accuracy: 88-93%
- Inference Speed: <15ms per frame (CUDA-accelerated)
- GPU Memory Usage: ~6-7GB (out of 8GB)

TROUBLESHOOTING:

CUDA not detected:
```bash
nvidia-smi
nvcc --version
python -c "import torch; print(torch.cuda.is_available())"
```

Out of GPU memory:
```bash
# Reduce batch_size to 16 in training/config.yaml
# Enable gradient checkpointing
# Clear CUDA cache: python -c "import torch; torch.cuda.empty_cache()"
```

CUDA version mismatch:
```bash
# Check CUDA version
nvidia-smi  # Look for CUDA Version
nvcc --version

# Install matching PyTorch
# For CUDA 11.8: pip install torch --index-url https://download.pytorch.org/whl/cu118
# For CUDA 12.1: pip install torch --index-url https://download.pytorch.org/whl/cu121
```

Slow training despite GPU:
```bash
# Verify GPU is being used
python -c "import torch; print(torch.cuda.current_device()); print(torch.cuda.get_device_name(0))"

# Check if data loading is bottleneck
# Increase num_workers in training config
```

Mixed precision for faster training (optional):
```bash
# Add to training script for 2x speedup
export TF_ENABLE_AUTO_MIXED_PRECISION=1  # TensorFlow
# Or use torch.cuda.amp for PyTorch
```

Execute these steps in order and report any errors. The entire process should take approximately 3-4 hours total with CUDA acceleration (vs 8+ hours on CPU).

PERFORMANCE COMPARISON:
- CPU Only: ~8-10 hours training
- 8GB VRAM + CUDA: ~2-3 hours training (3-4x faster)
- Inference: 15ms (CUDA) vs 50ms (CPU)
